{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All useful hyperparameters exists in the dicts, so that the contents of the dict is the only code that has to be changed between each test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#!rm -rf ./logs/\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import filters\n",
    "import scipy.ndimage as nd\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "    \n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell confugures all the nessesery information for the results file. File definition is found in the AnalyzeResults notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"epochs\" : 10,\n",
    "    \"batch_size\" : 1,\n",
    "    \"shuffle_buffer\" : 128\n",
    "} \n",
    "\n",
    "datasetParams = {\n",
    "    \"datasetDir\": '../../Datasets/DVRUP_normalized_conv2d/',\n",
    "    \"setsUsed\"  : ['Skogen', 'Hagen', 'Hytta'],\n",
    "    \"colors\"    : ['r', 'g', 'b'],\n",
    "    \"startNum\"  : [1, 1, 1],\n",
    "    \"numFiles\"  : [6, 4, 4],\n",
    "    \"valColors\" : ['r', 'g', 'b'],\n",
    "    \"valSetsUsed\" : ['Skogen'],\n",
    "    \"valStartNum\" : [7],\n",
    "    \"numValFiles\" : [7]\n",
    "}\n",
    "\n",
    "conv2D_args = {\n",
    "    \"kernel_size\" : (9,9),\n",
    "    \"activation\"  : \"relu\",\n",
    "    \"padding\" : \"same\"\n",
    "}\n",
    "\n",
    "deepL_args = {\n",
    "    \"kernel_size\" : (11,11),\n",
    "    \"activation\"  : \"relu\",\n",
    "    \"padding\" : \"same\"\n",
    "}\n",
    "\n",
    "out_params = {\n",
    "    \"filters\" : 1,\n",
    "    \"kernel_size\" : (1,1),\n",
    "    \"activation\"  : \"tanh\",\n",
    "    \"padding\" : \"same\"\n",
    "}\n",
    "\n",
    "modelGenParams = {\n",
    "    \"x\" : 640,\n",
    "    \"y\" : 360,\n",
    "    \"inChans\" : 3,\n",
    "    \"optimizer\" : \"adadelta\",\n",
    "    \"loss\" : \"mae\",\n",
    "    \"enc_layers\" : [[64, 1, 0, conv2D_args, False], [64, 2, 0, conv2D_args, True], [64, 2, 0, conv2D_args, False]],\n",
    "    \"mid_layers\" : [[128, 4, 0, deepL_args]],\n",
    "    \"dec_layers\" : [[64, 1, 0, conv2D_args, False], [64, 2, 0, conv2D_args, True], [64, 2, 0, conv2D_args, False]],\n",
    "    \"out_params\" : out_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputFiles(d, s, n, co, dsdir):\n",
    "    ds = []\n",
    "    for i in range(len(d)):\n",
    "        for j in range(s[i], 1 + n[i]):\n",
    "            for c in co:\n",
    "                ds.append(dsdir + d[i] + str(j) + c + '.tfrec')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(file, dir = \"./datasetDir/\", selc = 'r'):\n",
    "    X = np.load(dir + file +\"X\" + selc + \".npy\")[:, :, :, :]\n",
    "    Y = np.load(dir + file +\"Y\" + selc + \".npy\")[:, :, :, :]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showFrame(frame, title = 'Frame', show = True):\n",
    "    plt.imshow(frame)\n",
    "    plt.title(title)\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(ex):\n",
    "    features = {\n",
    "    'X': tf.io.FixedLenFeature([], tf.string),\n",
    "    'Y': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    ex = tf.io.parse_single_example(ex, features)\n",
    "    #Decoding the TFRecord\n",
    "    x = tf.io.decode_raw(\n",
    "        ex['X'], out_type=np.float32, little_endian=True, fixed_length=None, name=None\n",
    "    )\n",
    "    y = tf.io.decode_raw(\n",
    "        ex['Y'], out_type=np.float32, little_endian=True, fixed_length=None, name=None\n",
    "    )\n",
    "    # USING MINI DATAET! CHANGE BACK WHEN DONE! shape x (360, 640, 5). y (360, 640, 1)\n",
    "    x = tf.reshape(x, (360, 640, 3))\n",
    "    y = tf.reshape(y, (360, 640, 1))\n",
    "    return x, y\n",
    "\n",
    "def get_batched_dataset(filenames):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "\n",
    "    dataset = dataset.shuffle(parameters[\"shuffle_buffer\"])\n",
    "    dataset = dataset.batch(parameters[\"batch_size\"], drop_remainder=True) \n",
    "    dataset = dataset.prefetch(AUTO) #\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset():\n",
    "    return get_batched_dataset(datasetsToLoad)\n",
    "\n",
    "def get_validation_dataset():\n",
    "    return get_batched_dataset(valSetsToLoad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition layer implementation:\n",
    "# Adds last layer from encoding of same dimention to the last layer of the decoder step. \n",
    "# A storage solution must be implemented - if entype is encoder -> store layer in list. Return this list. \n",
    "# If entype is decoder -> add layer from provided list as the final step. \n",
    "# Make it selectable -> add flag\n",
    "# For each layer?\n",
    "\n",
    "# Test train for five epochs and combare with non add model! \n",
    "\n",
    "# lookup add layers\n",
    "# add values of dimentions? -> values\n",
    "\n",
    "\n",
    "def genLayers(layer, description, entype = 'mid', pLayers = [ ]):\n",
    "    \"\"\" Generates keras layers from list of description lists. [[filters, n_layers, dropout(0 => no dropout layer), add(/store) - bool]]\"\"\"\n",
    "    aLayers = [ ]\n",
    "    for l in description:\n",
    "        if entype == 'decoder':\n",
    "            layer = tf.keras.layers.UpSampling2D()(layer)\n",
    "        \n",
    "        if l[2] != 0:\n",
    "            layer = tf.keras.layers.Dropout(l[2])(layer)\n",
    "        for n in range(l[1]):\n",
    "            layer = tf.keras.layers.Conv2D(l[0], **l[3])(layer)\n",
    "        \n",
    "        if entype == 'encoder':\n",
    "            if l[4]:\n",
    "                # Save the last layer in a list so that it can be added back in during decoding\n",
    "                aLayers.append(layer)\n",
    "            layer = tf.keras.layers.MaxPooling2D(padding = 'same')(layer)\n",
    "            \n",
    "        elif entype == 'decoder' and l[4]:\n",
    "            # Add the stored layers from the encoder\n",
    "            layer = tf.keras.layers.add([layer, pLayers.pop()])\n",
    "    return [layer , aLayers]\n",
    "\n",
    "def generateModel(p):\n",
    "    \"\"\" Generate autoencoder with provided hyperparameters \"\"\"\n",
    "    input_layer = tf.keras.layers.Input(shape = (p[\"y\"], p[\"x\"], p[\"inChans\"]))\n",
    "    \n",
    "    #Generating encoder layers\n",
    "    layer, addLayers = genLayers(input_layer, p[\"enc_layers\"], entype = 'encoder')\n",
    "    print(addLayers)\n",
    "    #Generating middle layers\n",
    "    layer = genLayers(layer, p[\"mid_layers\"])[0]\n",
    "    \n",
    "    #Generating decoder layers\n",
    "    layer = genLayers(layer, p[\"dec_layers\"], entype = 'decoder' , pLayers = addLayers)[0]\n",
    "    \n",
    "    #OutputLayer\n",
    "    output_layer = tf.keras.layers.Conv2D(**p[\"out_params\"])(layer)\n",
    "    \n",
    "    #Creating model\n",
    "    model = tf.keras.Model(input_layer, output_layer)\n",
    "    model.compile(optimizer = 'adadelta', loss = p[\"loss\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetsToLoad = getInputFiles(datasetParams[\"setsUsed\"], \n",
    "                               datasetParams[\"startNum\"], \n",
    "                               datasetParams[\"numFiles\"], \n",
    "                               datasetParams[\"colors\"],\n",
    "                               datasetParams[\"datasetDir\"])\n",
    "\n",
    "valSetsToLoad = getInputFiles(datasetParams[\"valSetsUsed\"], \n",
    "                              datasetParams[\"valStartNum\"], \n",
    "                              datasetParams[\"numValFiles\"], \n",
    "                              datasetParams[\"valColors\"],\n",
    "                              datasetParams[\"datasetDir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = generateModel(modelGenParams)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n",
    "#                                                      histogram_freq=1,\n",
    "#                                                      profile_batch = '500,520')\n",
    "h = autoencoder.fit(get_training_dataset(), \n",
    "                    validation_data = get_validation_dataset(),  \n",
    "                    epochs = parameters[\"epochs\"], \n",
    "                    verbose = 1) \n",
    "#                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trHist = np.array([h.history['loss'],\n",
    "                   h.history['val_loss']])\n",
    "\n",
    "epochs = range(len(trHist[0])) # Get list of numbers in length of epochs\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs[0:100], trHist[0], 'r', label = \"Training Loss\")\n",
    "plt.plot(epochs[0:100], trHist[1], 'b', label = \"Validation Loss\")\n",
    "plt.title('Training and validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vX, vY = loadDataset('Skogen7_2a2b_', dir = '../../Datasets/DVRUP_1f_2f2b/', selc = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the dataset to the correct dimentions\n",
    "vX = vX[:, :, :, 1:4] / 256\n",
    "vY = vY[:, :, :] /256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 500\n",
    "valFrames = np.clip(autoencoder.predict(vX[f:f+1], batch_size = 1), 0.0, 1.0)\n",
    "showFrame(vX[f, :, :, 2])\n",
    "showFrame(valFrames[0, :, :, 0])\n",
    "showFrame(vY[f, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processed: ')\n",
    "print('Max: ', valFrames[0].max()  , '    Min:', valFrames[0].min()   , '    std: ', valFrames[0].std(),'          mean: ', valFrames[0].mean())\n",
    "print('Input: ')\n",
    "print('Max: ', vX[f, :, :, 0].max(), '    Min:', vX[f, :, :, 0].min() , '    std: ', vX[0].std(),' mean: ', vX[f, :, :, 0].mean())\n",
    "print('Output: ')\n",
    "print('Max: ', vY[f, :, :, 0].max(), '     Min:', vY[f, :, :, 0].min(), '    std: ', vY[0].std(),' mean: ', vY[f, :, :, 0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"Same as 119, but addition moved to second decoder layer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outN = '120'\n",
    "infoPath = '../TrainingResults/info/'\n",
    "a = np.array([comment, parameters, datasetParams, modelGenParams, trHist], dtype = object)\n",
    "np.save(infoPath + outN, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modPath = '../Models/'\n",
    "autoencoder.save(modPath + outN +'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Experiment',  outN, 'executed using tensorflow V', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the test video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Usage/DVRUP_IO.py\n",
    "inVid = '../../Datasets/video/PICT0039.AVI'\n",
    "outPath = '../../Datasets/video/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputVid = loadVideo(inVid, 100, 300, 0, 640, 60, 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = reshapeAndSplitVideo(inputVid)\n",
    "vid = processVideo(autoencoder, r, g, b, amp = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveVideo(vid, outPath + outN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
